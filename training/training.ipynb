{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "86bbbfb5-a0cc-462f-a0cf-023e679f652a",
   "metadata": {},
   "source": [
    "# Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b1f187f2-b3da-463b-9c09-06dc12b2dc10",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from torch.utils.data import Dataset, DataLoader, random_split\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "import matplotlib\n",
    "from matplotlib import pyplot as plt\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "from datasets import AASequenceDataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30273557-c70e-47b5-96c7-8d3fb33c8a1d",
   "metadata": {},
   "source": [
    "## Loading the dataset and splitting it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1056e89d-c702-4706-9a92-4a4fa5e69ec5",
   "metadata": {},
   "outputs": [],
   "source": [
    "sequence_dataset = AASequenceDataset('./data/merged_data_train.tsv', onehot_input=True, multihot_output=True)\n",
    "slen = len(sequence_dataset)\n",
    "val_set, train_set = random_split(sequence_dataset, [int(0.2 * slen), int(slen - int(0.2 * slen))], generator=torch.Generator().manual_seed(42))\n",
    "def my_collate(x):\n",
    "    return list(zip(*x))\n",
    "dataloader = DataLoader(train_set, batch_size=300,\n",
    "                        shuffle=True, num_workers=0, collate_fn=my_collate)\n",
    "val_dataloader = DataLoader(val_set, batch_size=10,\n",
    "                        shuffle=True, num_workers=0, collate_fn=my_collate)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f9f5f8f-9794-4723-90fa-a2d10a0954c8",
   "metadata": {},
   "source": [
    "### Model\n",
    "The model used for this example is a CNN model for only the amino acid sequence input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b385d642-9d3f-40a5-a520-79317c762b21",
   "metadata": {},
   "outputs": [],
   "source": [
    "class AASequenceModel(nn.Module):\n",
    "\n",
    "    def __init__(self, conv_depth=4, lin_depth=2):\n",
    "        super(AASequenceModel, self).__init__()\n",
    "        self.conv_depth = conv_depth\n",
    "        self.lin_depth = lin_depth\n",
    "        self.conv1 = nn.Conv1d(20,128,21, padding='same')\n",
    "        self.convHidden = nn.ModuleList([nn.Conv1d(128,128,21, padding='same') for i in range(self.conv_depth)])\n",
    "        #self.dropHidden = nn.ModuleList([nn.Dropout(0.3) for i in range(self.conv_depth)])\n",
    "        self.reluHidden = nn.ModuleList([nn.ELU() for i in range(self.conv_depth)])\n",
    "        self.linLayers = nn.ModuleList([nn.Linear(128, 128) for i in range(self.lin_depth)])\n",
    "        #self.dropLin = nn.ModuleList([nn.Dropout(0.3) for i in range(self.lin_depth)])\n",
    "        self.reluLin = nn.ModuleList([nn.ELU() for i in range(self.lin_depth)])\n",
    "        self.linLast = nn.Linear(128,1)\n",
    "        self.negCnt = 0\n",
    "        self.allCnt = 0\n",
    "        \n",
    "    def dying_relu(self):\n",
    "        return self.negCnt / self.allCnt\n",
    "\n",
    "    def forward(self, x):\n",
    "        self.negCnt = 0\n",
    "        self.allCnt = 0\n",
    "        y = torch.transpose(x, 1, 2)\n",
    "        y = self.conv1(y.float())\n",
    "        for i in range(self.conv_depth):\n",
    "            #y = self.dropHidden[i](y)\n",
    "            y = self.convHidden[i](y)\n",
    "            self.negCnt += torch.sum(y < 0)\n",
    "            self.allCnt += torch.numel(y)\n",
    "            y = self.reluHidden[i](y)\n",
    "        y = torch.transpose(y, 1, 2)\n",
    "        for i in range(self.lin_depth):\n",
    "            #y = self.dropLin[i](y)\n",
    "            y = self.linLayers[i](y)\n",
    "            self.negCnt += torch.sum(y < 0)\n",
    "            self.allCnt += torch.numel(y)\n",
    "            y = self.reluLin[i](y)\n",
    "        y = self.linLast(y)\n",
    "        return y"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "406c9159-882a-4c8b-bb1c-8568a0334565",
   "metadata": {},
   "source": [
    "## The training\n",
    "First we prepare a couple of things for training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5b0228d9-92a4-4816-a131-36c501a517c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "writer = SummaryWriter()\n",
    "model = AASequenceModel()\n",
    "loss_fn = nn.BCEWithLogitsLoss(pos_weight=torch.tensor(51.86))\n",
    "opt = optim.Adam(model.parameters(), lr=0.001)\n",
    "epoch_num = 5"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63121af2-ee44-4a57-9a82-32f36ae751db",
   "metadata": {},
   "source": [
    "We train the model and every certain number of steps we compute its performance on the validation set"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c9ec944-ab2a-47db-9817-48c044a3ac9b",
   "metadata": {},
   "source": [
    "## THINGS TO CHANGE\n",
    "- Weird bug (N,) doesnt work for the loss shape (N, 1) but this shape works\n",
    "- w = alpha * (1+r)/(1-r)\n",
    "- no_grad for performance calculations\n",
    "- use scikit-ln ROC AOC\n",
    "- ADAM\n",
    "- GeLU, ELU\n",
    "- Sequential Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4edf2d18-a88b-4df8-b4bf-3ae575253b76",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0\n"
     ]
    }
   ],
   "source": [
    "model.train()\n",
    "for epoch in range(epoch_num):\n",
    "    print(\"Epoch: \" + str(epoch))\n",
    "    for batch_num, (seq_batch, _, label_batch) in enumerate(dataloader):\n",
    "        batch_num = epoch*len(dataloader) + batch_num\n",
    "        opt.zero_grad()\n",
    "        seqs = []\n",
    "        labels = []\n",
    "        for i, seq in enumerate(seq_batch):\n",
    "            seq = torch.tensor(seq)\n",
    "            seq = seq.unsqueeze(dim=0)\n",
    "            labels.append(label_batch[i])\n",
    "            seqs.append(model(seq).squeeze())\n",
    "        seqs = torch.cat(seqs)\n",
    "        labels = torch.cat(labels)\n",
    "        loss = loss_fn(seqs, labels)\n",
    "        writer.add_scalar('Train/Loss', loss.item(), batch_num)\n",
    "        writer.add_scalar('Train/DyingReLU', model.dying_relu(), batch_num)\n",
    "        loss.backward()\n",
    "        opt.step()\n",
    "        if (batch_num % 10 == 0 and batch_num != 0):\n",
    "            # Model Evaluation\n",
    "            model.eval()\n",
    "            val_loss = 0\n",
    "            val_batch_cnt = 0\n",
    "            TP, TN, FP, FN = 0, 0, 0, 0\n",
    "            for seq_batch, _, label_batch in val_dataloader:\n",
    "                seqs = []\n",
    "                labels = []\n",
    "                for i, seq in enumerate(seq_batch):\n",
    "                    seq = torch.tensor(seq)\n",
    "                    seq = seq.unsqueeze(dim=0)\n",
    "                    labels.append(label_batch[i])\n",
    "                    seqs.append(model(seq).squeeze())\n",
    "                seqs = torch.cat(seqs)\n",
    "                labels = torch.cat(labels)\n",
    "                val_loss += loss_fn(seqs, labels).item()\n",
    "                seqs = seqs > 0\n",
    "                labels = labels > .5\n",
    "                TP += (seqs & labels).sum()\n",
    "                FP += (seqs & ~labels).sum()\n",
    "                TN += (~seqs & ~labels).sum()\n",
    "                FN += (~seqs & labels).sum()\n",
    "                val_batch_cnt += 1\n",
    "            val_loss /= val_batch_cnt\n",
    "            writer.add_scalar('Validation/Loss', val_loss, batch_num)\n",
    "            writer.add_scalar('Validation/Precision', TP/(TP+FP), batch_num)\n",
    "            writer.add_scalar('Validation/Recall', TP/(TP+FN), batch_num)\n",
    "            writer.add_scalar('Validation/Accuracy', (TP+TN)/(TP+FP+TN+FN), batch_num)\n",
    "            model.train()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
